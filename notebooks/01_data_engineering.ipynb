{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58 sensor CSVs in: mdm2 data files/Hourly count data\n",
      "Bad timestamps: 0\n",
      "Rows with missing lat/lon: 0\n",
      "Negative ped rows: 0\n",
      "Negative car rows: 0\n",
      "Negative cyc rows: 0\n",
      "Rows per sensor (min/max): 8784 8784\n",
      "Example sensors: [1, 35, 36, 37, 38, 39, 40, 41, 42, 43]\n",
      "Saved to: /Users/shavarshmelikyan/Desktop/mdm2 data files/big_table.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Change this to the full path if needed.\n",
    "# to implement, keep repositories on your computer in the following structure:\n",
    "#Desktop/mdm2 data files/README.txt, Sensor_Location.csv, Hourly count data (dir with all csv files); final big_table.csv will be saved in mdm2.. dir\n",
    "BASE_DIR = Path(\"mdm2 data files\")\n",
    "\n",
    "LOC_PATH = BASE_DIR / \"Sensor_Location.csv\"\n",
    "COUNTS_DIR = BASE_DIR / \"Hourly count data\"\n",
    "\n",
    "# --- 1) Load locations ---\n",
    "loc = pd.read_csv(LOC_PATH)\n",
    "\n",
    "# standardising column names \n",
    "loc_cols = {c.lower().strip(): c for c in loc.columns}\n",
    "# expected keys: sensornumber, latitude, longitude (or similar)\n",
    "sensor_col = loc_cols.get(\"sensornumber\", loc_cols.get(\"sensor\", None))\n",
    "lat_col    = loc_cols.get(\"latitude\",  loc_cols.get(\"lat\", None))\n",
    "lon_col    = loc_cols.get(\"longitude\", loc_cols.get(\"lon\", None))\n",
    "\n",
    "if sensor_col is None or lat_col is None or lon_col is None:\n",
    "    raise ValueError(f\"Unexpected Sensor_Location columns: {list(loc.columns)}\")\n",
    "\n",
    "loc = loc.rename(columns={sensor_col: \"sensor_id\", lat_col: \"latitude\", lon_col: \"longitude\"})\n",
    "loc[\"sensor_id\"] = loc[\"sensor_id\"].astype(int)\n",
    "\n",
    "# 2) Finding sensor files inside Hourly count data\n",
    "sensor_files = sorted(\n",
    "    [p for p in COUNTS_DIR.glob(\"*.csv\") if re.fullmatch(r\"\\d+\\.csv\", p.name)],\n",
    "    key=lambda p: int(p.stem)\n",
    ")\n",
    "\n",
    "print(f\"Found {len(sensor_files)} sensor CSVs in: {COUNTS_DIR}\")\n",
    "\n",
    "#3) Load + stack\n",
    "dfs = []\n",
    "for p in sensor_files:\n",
    "    sid = int(p.stem)\n",
    "    df = pd.read_csv(p)\n",
    "    df[\"sensor_id\"] = sid\n",
    "    dfs.append(df)\n",
    "\n",
    "big = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "#  4) Parse datetime + add basic time features\n",
    "# Most files have a column called 'date' that includes date+time to the hour\n",
    "if \"date\" not in big.columns:\n",
    "    raise ValueError(f\"No 'date' column found in counts data. Columns are: {list(big.columns)}\")\n",
    "\n",
    "big[\"datetime\"] = pd.to_datetime(big[\"date\"], errors=\"coerce\")\n",
    "big = big.drop(columns=[\"date\"])\n",
    "\n",
    "big[\"hour\"] = big[\"datetime\"].dt.hour\n",
    "big[\"date_only\"] = big[\"datetime\"].dt.date\n",
    "big[\"dow\"] = big[\"datetime\"].dt.dayofweek  # Monday=0\n",
    "\n",
    "#  5) Joining sensor locations \n",
    "big = big.merge(loc, on=\"sensor_id\", how=\"left\")\n",
    "\n",
    "# 6) checks\n",
    "print(\"Bad timestamps:\", big[\"datetime\"].isna().sum())\n",
    "print(\"Rows with missing lat/lon:\", big[\"latitude\"].isna().sum())\n",
    "\n",
    "for col in [\"ped\", \"car\", \"cyc\"]:\n",
    "    if col in big.columns:\n",
    "        print(f\"Negative {col} rows:\", (big[col] < 0).sum())\n",
    "    else:\n",
    "        print(f\"WARNING: column '{col}' not found. Available: {list(big.columns)}\")\n",
    "\n",
    "rows_per_sensor = big.groupby(\"sensor_id\").size().sort_values()\n",
    "print(\"Rows per sensor (min/max):\", rows_per_sensor.min(), rows_per_sensor.max())\n",
    "print(\"Example sensors:\", rows_per_sensor.index[:10].tolist())\n",
    "\n",
    "big.head()\n",
    "\n",
    "OUT_PATH = Path(\"mdm2 data files\") / \"big_table.csv\"\n",
    "big.to_csv(OUT_PATH, index=False)\n",
    "print(\"Saved to:\", OUT_PATH.resolve())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
